{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:28.074828Z",
     "iopub.status.busy": "2021-06-23T20:14:28.074328Z",
     "iopub.status.idle": "2021-06-23T20:14:28.945241Z",
     "shell.execute_reply": "2021-06-23T20:14:28.944389Z",
     "shell.execute_reply.started": "2021-06-23T18:25:43.508399Z"
    },
    "papermill": {
     "duration": 0.900715,
     "end_time": "2021-06-23T20:14:28.945397",
     "exception": false,
     "start_time": "2021-06-23T20:14:28.044682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/all_data.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test_public_expanded.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test_private_expanded.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/toxicity_individual_annotations.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/identity_individual_annotations.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/LICENSE\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.gitignore\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/README.md\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/MANIFEST.in\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/requirements.txt\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.coveragerc\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/setup.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/modeling_xlnet_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/optimization_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/conftest.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/modeling_gpt2_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/tokenization_transfo_xl_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/tokenization_xlnet_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/tokenization_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/tokenization_gpt2_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/modeling_transfo_xl_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/tokenization_openai_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/modeling_openai_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/tests/modeling_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/samples/test_sentencepiece.model\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/samples/input.txt\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/samples/sample_text.txt\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/bertology.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_transfo_xl.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/generation_xlnet.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_gpt2.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_openai_gpt.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_squad.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_classifier_dataset_utils.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_classifier.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_squad_dataset_utils.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/run_swag.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/extract_features.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/lm_finetuning/pregenerate_training_data.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/lm_finetuning/finetune_on_pregenerated.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/lm_finetuning/README.md\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/examples/lm_finetuning/simple_lm_finetuning.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.github/stale.yml\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/docker/Dockerfile\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/docs/imgs/warmup_cosine_hard_restarts_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/docs/imgs/warmup_cosine_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/docs/imgs/warmup_linear_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/docs/imgs/warmup_constant_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/docs/imgs/warmup_cosine_warm_restarts_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/notebooks/Comparing-TF-and-PT-models.ipynb\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/notebooks/Comparing-TF-and-PT-models-MLM-NSP.ipynb\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/notebooks/Comparing-TF-and-PT-models-SQuAD.ipynb\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/hubconfs/xlnet_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/hubconfs/gpt2_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/hubconfs/gpt_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/hubconfs/transformer_xl_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/hubconfs/bert_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/COMMIT_EDITMSG\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/config\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/packed-refs\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/FETCH_HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/ORIG_HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/index\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/description\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/info/exclude\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/refs/heads/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/refs/remotes/origin/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/refs/remotes/origin/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/prepare-commit-msg.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/update.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/pre-push.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/pre-rebase.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/pre-applypatch.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/pre-commit.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/commit-msg.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/post-update.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/pre-receive.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/fsmonitor-watchman.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/hooks/applypatch-msg.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/logs/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/logs/refs/heads/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/logs/refs/remotes/origin/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/logs/refs/remotes/origin/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/75/23923cb4f8fb3d055764c88ebe2fc781a0995e\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/1a/5fadac6d61e3072c0cc8408b1dd361745c661c\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/bb/aa0609e4a6920355985fbd38b5e73ad2c1fbc6\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/7f/7d22b73514f5f98b616f459f9bcc6399fd4f66\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/58/af5cfb148a629a274c8a91b23cad63e1fc6c5f\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/pack/pack-33aef363ba97c2cf666d9f07416a06f16656eb36.idx\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/pack/pack-3e53aa2061883b29c981ad419c6fe0ee56310ac4.pack\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/pack/pack-33aef363ba97c2cf666d9f07416a06f16656eb36.pack\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/pack/pack-3e53aa2061883b29c981ad419c6fe0ee56310ac4.idx\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/11/e9603fda71037a184db7469c348f3e4874f28b\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/0b/166e2b09034c4462311a423c68a7d2755e68bc\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.git/objects/ee/2d87b488c35e0b2cd7dc4b86d29a4271b46a0d\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_transfo_xl_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_gpt2.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_xlnet_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_openai_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_xlnet_utilities.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/file_utils.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_xlnet.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_transfo_xl.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_transfo_xl_utilities.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_openai.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/optimization.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/optimization_openai.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_gpt2.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_openai.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_gpt2_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/__init__.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_transfo_xl.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/__main__.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_xlnet.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-BERT/.circleci/config.yml\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/LICENSE\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.gitignore\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/README.md\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/MANIFEST.in\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/requirements.txt\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.coveragerc\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/setup.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/modeling_xlnet_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/optimization_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/conftest.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/modeling_gpt2_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/tokenization_transfo_xl_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/tokenization_xlnet_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/tokenization_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/tokenization_gpt2_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/modeling_transfo_xl_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/tokenization_openai_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/modeling_openai_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/tests/modeling_test.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/samples/test_sentencepiece.model\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/samples/input.txt\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/samples/sample_text.txt\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/bertology.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_transfo_xl.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/generation_xlnet.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_gpt2.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_openai_gpt.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_squad.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_classifier_dataset_utils.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_classifier.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_squad_dataset_utils.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/run_swag.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/extract_features.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/lm_finetuning/pregenerate_training_data.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/lm_finetuning/finetune_on_pregenerated.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/lm_finetuning/README.md\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/examples/lm_finetuning/simple_lm_finetuning.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.github/stale.yml\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/docker/Dockerfile\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/docs/imgs/warmup_cosine_hard_restarts_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/docs/imgs/warmup_cosine_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/docs/imgs/warmup_linear_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/docs/imgs/warmup_constant_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/docs/imgs/warmup_cosine_warm_restarts_schedule.png\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/notebooks/Comparing-TF-and-PT-models.ipynb\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/notebooks/Comparing-TF-and-PT-models-MLM-NSP.ipynb\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/notebooks/Comparing-TF-and-PT-models-SQuAD.ipynb\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/hubconfs/xlnet_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/hubconfs/gpt2_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/hubconfs/gpt_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/hubconfs/transformer_xl_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/hubconfs/bert_hubconf.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/COMMIT_EDITMSG\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/config\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/packed-refs\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/FETCH_HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/ORIG_HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/index\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/description\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/info/exclude\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/refs/heads/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/refs/remotes/origin/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/refs/remotes/origin/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/prepare-commit-msg.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/update.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/pre-push.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/pre-rebase.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/pre-applypatch.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/pre-commit.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/commit-msg.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/post-update.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/pre-receive.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/fsmonitor-watchman.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/hooks/applypatch-msg.sample\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/logs/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/logs/refs/heads/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/logs/refs/remotes/origin/master\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/logs/refs/remotes/origin/HEAD\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/75/23923cb4f8fb3d055764c88ebe2fc781a0995e\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/1a/5fadac6d61e3072c0cc8408b1dd361745c661c\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/bb/aa0609e4a6920355985fbd38b5e73ad2c1fbc6\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/7f/7d22b73514f5f98b616f459f9bcc6399fd4f66\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/58/af5cfb148a629a274c8a91b23cad63e1fc6c5f\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/pack/pack-33aef363ba97c2cf666d9f07416a06f16656eb36.idx\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/pack/pack-3e53aa2061883b29c981ad419c6fe0ee56310ac4.pack\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/pack/pack-33aef363ba97c2cf666d9f07416a06f16656eb36.pack\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/pack/pack-3e53aa2061883b29c981ad419c6fe0ee56310ac4.idx\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/11/e9603fda71037a184db7469c348f3e4874f28b\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/0b/166e2b09034c4462311a423c68a7d2755e68bc\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.git/objects/ee/2d87b488c35e0b2cd7dc4b86d29a4271b46a0d\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_transfo_xl_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_gpt2.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_xlnet_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_openai_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_xlnet_utilities.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/file_utils.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_xlnet.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_transfo_xl.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_transfo_xl_utilities.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_openai.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/optimization.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/optimization_openai.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_gpt2.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/tokenization_openai.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/convert_gpt2_checkpoint_to_pytorch.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/__init__.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_transfo_xl.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/__main__.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling_xlnet.py\n",
      "/kaggle/input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/.circleci/config.yml\n",
      "/kaggle/input/gensim-embeddings-dataset/crawl-300d-2M.gensim\n",
      "/kaggle/input/gensim-embeddings-dataset/GoogleNews-vectors-negative300.gensim\n",
      "/kaggle/input/gensim-embeddings-dataset/paragram_300_sl999.gensim.vectors.npy\n",
      "/kaggle/input/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim\n",
      "/kaggle/input/gensim-embeddings-dataset/numberbatch-en.gensim.vectors.npy\n",
      "/kaggle/input/gensim-embeddings-dataset/glove.840B.300d.gensim\n",
      "/kaggle/input/gensim-embeddings-dataset/crawl-300d-2M.gensim.vectors.npy\n",
      "/kaggle/input/gensim-embeddings-dataset/glove.twitter.27B.200d.gensim.vectors.npy\n",
      "/kaggle/input/gensim-embeddings-dataset/numberbatch-en.gensim\n",
      "/kaggle/input/gensim-embeddings-dataset/glove.840B.300d.gensim.vectors.npy\n",
      "/kaggle/input/gensim-embeddings-dataset/paragram_300_sl999.gensim\n",
      "/kaggle/input/gensim-embeddings-dataset/GoogleNews-vectors-negative300.gensim.vectors.npy\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/config.json\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/merges.txt\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/special_tokens.txt\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/vocab.json\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/loss_log.txt\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/pytorch_model.bin\n",
      "/kaggle/input/jigsawmodels/gpt2_29bin_350seq_aus/gpt2_29bin_350seq_aus/submission.csv\n",
      "/kaggle/input/jigsawmodels/bert_small_v2_29bin_naus_300seq/bert_small_v2_29bin_naus_300seq/config.json\n",
      "/kaggle/input/jigsawmodels/bert_small_v2_29bin_naus_300seq/bert_small_v2_29bin_naus_300seq/loss_log.txt\n",
      "/kaggle/input/jigsawmodels/bert_small_v2_29bin_naus_300seq/bert_small_v2_29bin_naus_300seq/pytorch_model.bin\n",
      "/kaggle/input/jigsawmodels/bert_small_v2_29bin_naus_300seq/bert_small_v2_29bin_naus_300seq/submission.csv\n",
      "/kaggle/input/jigsawmodels/bert_small_v2_29bin_naus_300seq/bert_small_v2_29bin_naus_300seq/vocab.txt\n",
      "/kaggle/input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/config.json\n",
      "/kaggle/input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/loss_log.txt\n",
      "/kaggle/input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/pytorch_model.bin\n",
      "/kaggle/input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/submission.csv\n",
      "/kaggle/input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/vocab.txt\n",
      "/kaggle/input/jigsawmodels/xlnet_large_9bin_220seq/xlnet_large_9bin_220seq/config.json\n",
      "/kaggle/input/jigsawmodels/xlnet_large_9bin_220seq/xlnet_large_9bin_220seq/spiece.model\n",
      "/kaggle/input/jigsawmodels/xlnet_large_9bin_220seq/xlnet_large_9bin_220seq/special_tokens.txt\n",
      "/kaggle/input/jigsawmodels/xlnet_large_9bin_220seq/xlnet_large_9bin_220seq/loss_log.txt\n",
      "/kaggle/input/jigsawmodels/xlnet_large_9bin_220seq/xlnet_large_9bin_220seq/pytorch_model.bin\n",
      "/kaggle/input/jigsawmodels/xlnet_large_9bin_220seq/xlnet_large_9bin_220seq/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:28.992089Z",
     "iopub.status.busy": "2021-06-23T20:14:28.991493Z",
     "iopub.status.idle": "2021-06-23T20:14:36.925128Z",
     "shell.execute_reply": "2021-06-23T20:14:36.924614Z",
     "shell.execute_reply.started": "2021-06-23T18:25:44.145224Z"
    },
    "papermill": {
     "duration": 7.958471,
     "end_time": "2021-06-23T20:14:36.925277",
     "exception": false,
     "start_time": "2021-06-23T20:14:28.966806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "Ttokenizer = TreebankWordTokenizer()\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "import sys\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:36.969463Z",
     "iopub.status.busy": "2021-06-23T20:14:36.968746Z",
     "iopub.status.idle": "2021-06-23T20:14:36.971118Z",
     "shell.execute_reply": "2021-06-23T20:14:36.971488Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.673542Z"
    },
    "papermill": {
     "duration": 0.026208,
     "end_time": "2021-06-23T20:14:36.971611",
     "exception": false,
     "start_time": "2021-06-23T20:14:36.945403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "package_dir = \"../input/pytorchpretrainedberthaqishen/pytorch-pretrained-bert/pytorch-pretrained-BERT/\"\n",
    "sys.path = [package_dir] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.017205Z",
     "iopub.status.busy": "2021-06-23T20:14:37.016689Z",
     "iopub.status.idle": "2021-06-23T20:14:37.164083Z",
     "shell.execute_reply": "2021-06-23T20:14:37.163630Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.685346Z"
    },
    "papermill": {
     "duration": 0.173196,
     "end_time": "2021-06-23T20:14:37.164245",
     "exception": false,
     "start_time": "2021-06-23T20:14:36.991049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "import emoji\n",
    "import unicodedata\n",
    "import multiprocessing\n",
    "from functools import partial, lru_cache\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, BertModel, BertPreTrainedModel\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling_gpt2 import GPT2Config, GPT2Model, GPT2PreTrainedModel\n",
    "from pytorch_pretrained_bert.tokenization_gpt2 import GPT2Tokenizer\n",
    "from pytorch_pretrained_bert.modeling_xlnet import XLNetConfig, XLNetModel, XLNetPreTrainedModel\n",
    "from pytorch_pretrained_bert.tokenization_xlnet import XLNetTokenizer\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "Ttokenizer = TreebankWordTokenizer()\n",
    "\n",
    "import warnings\n",
    "import traceback\n",
    "warnings.filterwarnings(action='once')\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.209859Z",
     "iopub.status.busy": "2021-06-23T20:14:37.209228Z",
     "iopub.status.idle": "2021-06-23T20:14:37.215298Z",
     "shell.execute_reply": "2021-06-23T20:14:37.214864Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.923808Z"
    },
    "papermill": {
     "duration": 0.031171,
     "end_time": "2021-06-23T20:14:37.215418",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.184247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Adding progress bars for monitoring\n",
    "def is_interactive():\n",
    "   return 'SHLVL' not in os.environ\n",
    "  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3'\n",
    "\n",
    "if not is_interactive():\n",
    "    def nop(it, *a, **k):\n",
    "        return it\n",
    "\n",
    "    tqdm = nop\n",
    "\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019614,
     "end_time": "2021-06-23T20:14:37.254725",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.235111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading pretrained Gensim Embedding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.298930Z",
     "iopub.status.busy": "2021-06-23T20:14:37.298189Z",
     "iopub.status.idle": "2021-06-23T20:14:37.300492Z",
     "shell.execute_reply": "2021-06-23T20:14:37.300894Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.935631Z"
    },
    "papermill": {
     "duration": 0.026289,
     "end_time": "2021-06-23T20:14:37.301010",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.274721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CRAWL_EMBEDDING_PATH = \"../input/gensim-embeddings-dataset/crawl-300d-2M.gensim\"\n",
    "GLOVE_EMBEDDING_PATH = \"../input/gensim-embeddings-dataset/glove.840B.300d.gensim\"\n",
    "GOOGLE_EMBEDDING_PATH = \"../input/gensim-embeddings-dataset/GoogleNews-vectors-negative300.gensim\"\n",
    "PARAGRAM_EMBEDDING_PATH = \"../input/gensim-embeddings-dataset/paragram_300_sl999.gensim\"\n",
    "\n",
    "\n",
    "NUM_MODELS = 1\n",
    "LSTM_UNITS = 128\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "MAX_LEN = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.346950Z",
     "iopub.status.busy": "2021-06-23T20:14:37.346254Z",
     "iopub.status.idle": "2021-06-23T20:14:37.349081Z",
     "shell.execute_reply": "2021-06-23T20:14:37.348688Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.94318Z"
    },
    "papermill": {
     "duration": 0.028303,
     "end_time": "2021-06-23T20:14:37.349199",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.320896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "\n",
    "def load_embeddings(path):\n",
    "    with open(path) as f:\n",
    "        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n",
    "\n",
    "\n",
    "def build_matrix(word_index, path):\n",
    "    embedding_index = load_embeddings(path)\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            embedding_matrix[i] = embedding_index[word]\n",
    "        except KeyError:\n",
    "            unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.400233Z",
     "iopub.status.busy": "2021-06-23T20:14:37.396057Z",
     "iopub.status.idle": "2021-06-23T20:14:37.402284Z",
     "shell.execute_reply": "2021-06-23T20:14:37.402690Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.955863Z"
    },
    "papermill": {
     "duration": 0.033904,
     "end_time": "2021-06-23T20:14:37.402803",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.368899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def train_model(model, train, test, loss_fn, output_dim, lr=0.001,\n",
    "                batch_size=512, n_epochs=4,\n",
    "                enable_checkpoint_ensemble=True):\n",
    "    param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
    "    optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    all_test_preds = []\n",
    "    checkpoint_weights = [2 ** epoch for epoch in range(n_epochs)]\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        for data in tqdm(train_loader, disable=False):\n",
    "            x_batch = data[:-1]\n",
    "            y_batch = data[-1]\n",
    "\n",
    "            y_pred = model(*x_batch)            \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            \n",
    "        model.eval()\n",
    "        test_preds = np.zeros((len(test), output_dim))\n",
    "    \n",
    "        for i, x_batch in enumerate(test_loader):\n",
    "            y_pred = sigmoid(model(*x_batch).detach().cpu().numpy())\n",
    "\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred\n",
    "\n",
    "        all_test_preds.append(test_preds)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "              epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "\n",
    "    if enable_checkpoint_ensemble:\n",
    "        test_preds = np.average(all_test_preds, weights=checkpoint_weights, axis=0)    \n",
    "    else:\n",
    "        test_preds = all_test_preds[-1]\n",
    "        \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.454380Z",
     "iopub.status.busy": "2021-06-23T20:14:37.453657Z",
     "iopub.status.idle": "2021-06-23T20:14:37.455819Z",
     "shell.execute_reply": "2021-06-23T20:14:37.456235Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.971933Z"
    },
    "papermill": {
     "duration": 0.033692,
     "end_time": "2021-06-23T20:14:37.456353",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.422661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "    \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_aux_targets):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "    \n",
    "        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        \n",
    "        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n",
    "        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_lstm2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.510637Z",
     "iopub.status.busy": "2021-06-23T20:14:37.504141Z",
     "iopub.status.idle": "2021-06-23T20:14:37.513003Z",
     "shell.execute_reply": "2021-06-23T20:14:37.512617Z",
     "shell.execute_reply.started": "2021-06-23T18:25:51.987432Z"
    },
    "papermill": {
     "duration": 0.036974,
     "end_time": "2021-06-23T20:14:37.513120",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.476146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbols_to_isolate = '.,?!-;*\"…:—()%#$&_/@＼・ω+=”“[]^–>\\\\°<~•≠™ˈʊɒ∞§{}·τα❤☺ɡ|¢→̶`❥━┣┫┗Ｏ►★©―ɪ✔®\\x96\\x92●£♥➤´¹☕≈÷♡◐║▬′ɔː€۩۞†μ✒➥═☆ˌ◄½ʻπδηλσερνʃ✬ＳＵＰＥＲＩＴ☻±♍µº¾✓◾؟．⬅℅»Вав❣⋅¿¬♫ＣＭβ█▓▒░⇒⭐›¡₂₃❧▰▔◞▀▂▃▄▅▆▇↙γ̄″☹➡«φ⅓„✋：¥̲̅́∙‛◇✏▷❓❗¶˚˙）сиʿ✨。ɑ\\x80◕！％¯−ﬂﬁ₁²ʌ¼⁴⁄₄⌠♭✘╪▶☭✭♪☔☠♂☃☎✈✌✰❆☙○‣⚓年∎ℒ▪▙☏⅛ｃａｓǀ℮¸ｗ‚∼‖ℳ❄←☼⋆ʒ⊂、⅔¨͡๏⚾⚽Φ×θ￦？（℃⏩☮⚠月✊❌⭕▸■⇌☐☑⚡☄ǫ╭∩╮，例＞ʕɐ̣Δ₀✞┈╱╲▏▕┃╰▊▋╯┳┊≥☒↑☝ɹ✅☛♩☞ＡＪＢ◔◡↓♀⬆̱ℏ\\x91⠀ˤ╚↺⇤∏✾◦♬³の｜／∵∴√Ω¤☜▲↳▫‿⬇✧ｏｖｍ－２０８＇‰≤∕ˆ⚜☁'\n",
    "symbols_to_delete = '\\n🍕\\r🐵😑\\xa0\\ue014\\t\\uf818\\uf04a\\xad😢🐶️\\uf0e0😜😎👊\\u200b\\u200e😁عدويهصقأناخلىبمغر😍💖💵Е👎😀😂\\u202a\\u202c🔥😄🏻💥ᴍʏʀᴇɴᴅᴏᴀᴋʜᴜʟᴛᴄᴘʙғᴊᴡɢ😋👏שלוםבי😱‼\\x81エンジ故障\\u2009🚌ᴵ͞🌟😊😳😧🙀😐😕\\u200f👍😮😃😘אעכח💩💯⛽🚄🏼ஜ😖ᴠ🚲‐😟😈💪🙏🎯🌹😇💔😡\\x7f👌ἐὶήιὲκἀίῃἴξ🙄Ｈ😠\\ufeff\\u2028😉😤⛺🙂\\u3000تحكسة👮💙فزط😏🍾🎉😞\\u2008🏾😅😭👻😥😔😓🏽🎆🍻🍽🎶🌺🤔😪\\x08‑🐰🐇🐱🙆😨🙃💕𝘊𝘦𝘳𝘢𝘵𝘰𝘤𝘺𝘴𝘪𝘧𝘮𝘣💗💚地獄谷улкнПоАН🐾🐕😆ה🔗🚽歌舞伎🙈😴🏿🤗🇺🇸мυтѕ⤵🏆🎃😩\\u200a🌠🐟💫💰💎эпрд\\x95🖐🙅⛲🍰🤐👆🙌\\u2002💛🙁👀🙊🙉\\u2004ˢᵒʳʸᴼᴷᴺʷᵗʰᵉᵘ\\x13🚬🤓\\ue602😵άοόςέὸתמדףנרךצט😒͝🆕👅👥👄🔄🔤👉👤👶👲🔛🎓\\uf0b7\\uf04c\\x9f\\x10成都😣⏺😌🤑🌏😯ех😲Ἰᾶὁ💞🚓🔔📚🏀👐\\u202d💤🍇\\ue613小土豆🏡❔⁉\\u202f👠》कर्मा🇹🇼🌸蔡英文🌞🎲レクサス😛外国人关系Сб💋💀🎄💜🤢َِьыгя不是\\x9c\\x9d🗑\\u2005💃📣👿༼つ༽😰ḷЗз▱ц￼🤣卖温哥华议会下降你失去所有的钱加拿大坏税骗子🐝ツ🎅\\x85🍺آإشء🎵🌎͟ἔ油别克🤡🤥😬🤧й\\u2003🚀🤴ʲшчИОРФДЯМюж😝🖑ὐύύ特殊作戦群щ💨圆明园קℐ🏈😺🌍⏏ệ🍔🐮🍁🍆🍑🌮🌯🤦\\u200d𝓒𝓲𝓿𝓵안영하세요ЖљКћ🍀😫🤤ῦ我出生在了可以说普通话汉语好极🎼🕺🍸🥂🗽🎇🎊🆘🤠👩🖒🚪天一家⚲\\u2006⚭⚆⬭⬯⏖新✀╌🇫🇷🇩🇪🇮🇬🇧😷🇨🇦ХШ🌐\\x1f杀鸡给猴看ʁ𝗪𝗵𝗲𝗻𝘆𝗼𝘂𝗿𝗮𝗹𝗶𝘇𝗯𝘁𝗰𝘀𝘅𝗽𝘄𝗱📺ϖ\\u2000үսᴦᎥһͺ\\u2007հ\\u2001ɩｙｅ൦ｌƽｈ𝐓𝐡𝐞𝐫𝐮𝐝𝐚𝐃𝐜𝐩𝐭𝐢𝐨𝐧Ƅᴨןᑯ໐ΤᏧ௦Іᴑ܁𝐬𝐰𝐲𝐛𝐦𝐯𝐑𝐙𝐣𝐇𝐂𝐘𝟎ԜТᗞ౦〔Ꭻ𝐳𝐔𝐱𝟔𝟓𝐅🐋ﬃ💘💓ё𝘥𝘯𝘶💐🌋🌄🌅𝙬𝙖𝙨𝙤𝙣𝙡𝙮𝙘𝙠𝙚𝙙𝙜𝙧𝙥𝙩𝙪𝙗𝙞𝙝𝙛👺🐷ℋ𝐀𝐥𝐪🚶𝙢Ἱ🤘ͦ💸ج패티Ｗ𝙇ᵻ👂👃ɜ🎫\\uf0a7БУі🚢🚂ગુજરાતીῆ🏃𝓬𝓻𝓴𝓮𝓽𝓼☘﴾̯﴿₽\\ue807𝑻𝒆𝒍𝒕𝒉𝒓𝒖𝒂𝒏𝒅𝒔𝒎𝒗𝒊👽😙\\u200cЛ‒🎾👹⎌🏒⛸公寓养宠物吗🏄🐀🚑🤷操美𝒑𝒚𝒐𝑴🤙🐒欢迎来到阿拉斯ספ𝙫🐈𝒌𝙊𝙭𝙆𝙋𝙍𝘼𝙅ﷻ🦄巨收赢得白鬼愤怒要买额ẽ🚗🐳𝟏𝐟𝟖𝟑𝟕𝒄𝟗𝐠𝙄𝙃👇锟斤拷𝗢𝟳𝟱𝟬⦁マルハニチロ株式社⛷한국어ㄸㅓ니͜ʖ𝘿𝙔₵𝒩ℯ𝒾𝓁𝒶𝓉𝓇𝓊𝓃𝓈𝓅ℴ𝒻𝒽𝓀𝓌𝒸𝓎𝙏ζ𝙟𝘃𝗺𝟮𝟭𝟯𝟲👋🦊多伦🐽🎻🎹⛓🏹🍷🦆为和中友谊祝贺与其想象对法如直接问用自己猜本传教士没积唯认识基督徒曾经让相信耶稣复活死怪他但当们聊些政治题时候战胜因圣把全堂结婚孩恐惧且栗谓这样还♾🎸🤕🤒⛑🎁批判检讨🏝🦁🙋😶쥐스탱트뤼도석유가격인상이경제황을렵게만들지않록잘관리해야합다캐나에서대마초와화약금의품런성분갈때는반드시허된사용🔫👁凸ὰ💲🗯𝙈Ἄ𝒇𝒈𝒘𝒃𝑬𝑶𝕾𝖙𝖗𝖆𝖎𝖌𝖍𝖕𝖊𝖔𝖑𝖉𝖓𝖐𝖜𝖞𝖚𝖇𝕿𝖘𝖄𝖛𝖒𝖋𝖂𝕴𝖟𝖈𝕸👑🚿💡知彼百\\uf005𝙀𝒛𝑲𝑳𝑾𝒋𝟒😦𝙒𝘾𝘽🏐𝘩𝘨ὼṑ𝑱𝑹𝑫𝑵𝑪🇰🇵👾ᓇᒧᔭᐃᐧᐦᑳᐨᓃᓂᑲᐸᑭᑎᓀᐣ🐄🎈🔨🐎🤞🐸💟🎰🌝🛳点击查版🍭𝑥𝑦𝑧ＮＧ👣\\uf020っ🏉ф💭🎥Ξ🐴👨🤳🦍\\x0b🍩𝑯𝒒😗𝟐🏂👳🍗🕉🐲چی𝑮𝗕𝗴🍒ꜥⲣⲏ🐑⏰鉄リ事件ї💊「」\\uf203\\uf09a\\uf222\\ue608\\uf202\\uf099\\uf469\\ue607\\uf410\\ue600燻製シ虚偽屁理屈Г𝑩𝑰𝒀𝑺🌤𝗳𝗜𝗙𝗦𝗧🍊ὺἈἡχῖΛ⤏🇳𝒙ψՁմեռայինրւդձ冬至ὀ𝒁🔹🤚🍎𝑷🐂💅𝘬𝘱𝘸𝘷𝘐𝘭𝘓𝘖𝘹𝘲𝘫کΒώ💢ΜΟΝΑΕ🇱♲𝝈↴💒⊘Ȼ🚴🖕🖤🥘📍👈➕🚫🎨🌑🐻𝐎𝐍𝐊𝑭🤖🎎😼🕷ｇｒｎｔｉｄｕｆｂｋ𝟰🇴🇭🇻🇲𝗞𝗭𝗘𝗤👼📉🍟🍦🌈🔭《🐊🐍\\uf10aლڡ🐦\\U0001f92f\\U0001f92a🐡💳ἱ🙇𝗸𝗟𝗠𝗷🥜さようなら🔼'\n",
    "CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "\n",
    "isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\n",
    "remove_dict = {ord(c):f'' for c in symbols_to_delete}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.556850Z",
     "iopub.status.busy": "2021-06-23T20:14:37.556192Z",
     "iopub.status.idle": "2021-06-23T20:14:37.558863Z",
     "shell.execute_reply": "2021-06-23T20:14:37.558477Z",
     "shell.execute_reply.started": "2021-06-23T18:25:52.006681Z"
    },
    "papermill": {
     "duration": 0.026091,
     "end_time": "2021-06-23T20:14:37.558964",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.532873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessSymbols(x):\n",
    "    for k, v in CONTRACTION_MAPPING.items():\n",
    "        x = x.replace(' %s ' % k, ' %s ' % v)\n",
    "    x = x.str.translate(remove_dict)\n",
    "    x = x.str.translate(isolate_dict)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.606531Z",
     "iopub.status.busy": "2021-06-23T20:14:37.605738Z",
     "iopub.status.idle": "2021-06-23T20:14:37.608166Z",
     "shell.execute_reply": "2021-06-23T20:14:37.607758Z",
     "shell.execute_reply.started": "2021-06-23T18:25:52.020369Z"
    },
    "papermill": {
     "duration": 0.029079,
     "end_time": "2021-06-23T20:14:37.608268",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.579189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pandas multiprocessing\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    data= preprocessSymbols(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.662151Z",
     "iopub.status.busy": "2021-06-23T20:14:37.654952Z",
     "iopub.status.idle": "2021-06-23T20:14:37.664558Z",
     "shell.execute_reply": "2021-06-23T20:14:37.664056Z",
     "shell.execute_reply.started": "2021-06-23T18:26:14.89564Z"
    },
    "papermill": {
     "duration": 0.03677,
     "end_time": "2021-06-23T20:14:37.664653",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.627883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XLNetForJigSaw(XLNetPreTrainedModel):\n",
    "    def __init__(self, config, out_dim):\n",
    "        \n",
    "        super(XLNetForJigSaw, self).__init__(config)\n",
    "        self.attn_type = config.attn_type\n",
    "        self.same_length = config.same_length\n",
    "        self.summary_type = \"last\"\n",
    "\n",
    "        self.transformer = XLNetModel(config, output_attentions=False, keep_multihead_output=False)\n",
    "        self.dense = nn.Linear(config.d_model, config.d_model)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.linear = nn.Linear(config.d_model, out_dim, bias=True)\n",
    "        self.apply(self.init_xlnet_weights)\n",
    "\n",
    "    def forward(self, input_ids, seg_id=None, input_mask=None,\n",
    "                mems=None, perm_mask=None, target_mapping=None, inp_q=None,\n",
    "                target=None, output_all_encoded_layers=True, head_mask=None, **kargs):\n",
    "\n",
    "        output, hidden_states, new_mems = self.transformer(input_ids, seg_id, input_mask,\n",
    "                                            mems, perm_mask, target_mapping, inp_q,\n",
    "                                            output_all_encoded_layers, head_mask)\n",
    "        first_token_tensor = output[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "\n",
    "        return self.linear(pooled_output)\n",
    "    \n",
    "class GPT2ClassificationHeadModel(GPT2PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, clf_dropout=0.4, out_dim=8):\n",
    "        super(GPT2ClassificationHeadModel, self).__init__(config)\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.linear = nn.Linear(config.n_embd * 2, out_dim)\n",
    "\n",
    "        nn.init.normal_(self.linear.weight, std = 0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def set_num_special_tokens(self, num_special_tokens):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None, **kwargs):\n",
    "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
    "        if isinstance(hidden_states, list):\n",
    "            hidden_states = hidden_states[-1]\n",
    "        avg_pool = torch.mean(hidden_states, 1)\n",
    "        max_pool, _ = torch.max(hidden_states, 1)\n",
    "        h_conc = torch.cat((avg_pool, max_pool), 1)\n",
    "        return self.linear(h_conc)\n",
    "    \n",
    "    \n",
    "class BertForJigsaw(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, out_dim=7):\n",
    "        super(BertForJigsaw, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.linear = nn.Linear(config.hidden_size, out_dim)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.linear(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.711483Z",
     "iopub.status.busy": "2021-06-23T20:14:37.710789Z",
     "iopub.status.idle": "2021-06-23T20:14:37.713531Z",
     "shell.execute_reply": "2021-06-23T20:14:37.713132Z",
     "shell.execute_reply.started": "2021-06-23T18:26:25.075367Z"
    },
    "papermill": {
     "duration": 0.029174,
     "end_time": "2021-06-23T20:14:37.713633",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.684459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_line(row, max_seq_length, tokenizer, model_name='bert'):\n",
    "    guid = row['id']\n",
    "    text_a = row['comment_text']\n",
    "\n",
    "    if 'label' in row.keys():\n",
    "        label = row['label']\n",
    "    else:\n",
    "        label = None\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(text_a)\n",
    "\n",
    "    if 'bert' in model_name:\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    else:\n",
    "        if len(tokens_a) > max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "        tokens = tokens_a\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens_a)\n",
    "\n",
    "    segment_ids = [0] * len(tokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    padding = [0] * (max_seq_length - len(input_ids))\n",
    "    input_ids += padding\n",
    "    input_mask += padding\n",
    "    segment_ids += padding\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.759507Z",
     "iopub.status.busy": "2021-06-23T20:14:37.758875Z",
     "iopub.status.idle": "2021-06-23T20:14:37.762443Z",
     "shell.execute_reply": "2021-06-23T20:14:37.763014Z",
     "shell.execute_reply.started": "2021-06-23T18:26:28.253377Z"
    },
    "papermill": {
     "duration": 0.029941,
     "end_time": "2021-06-23T20:14:37.763186",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.733245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Def functions done! Time past 0.96 secs\n"
     ]
    }
   ],
   "source": [
    "def get_input_data(test_data):\n",
    "    all_input_ids, all_input_mask,  all_segment_ids, all_label_ids = [], [], [], []\n",
    "    for i, (input_ids, input_mask, segment_ids, label) in test_data.items():\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_input_mask.append(input_mask)\n",
    "        all_segment_ids.append(segment_ids)\n",
    "        all_label_ids.append(label)\n",
    "    all_input_ids = torch.tensor(all_input_ids, dtype=torch.long)\n",
    "    all_input_mask = torch.tensor(all_input_mask, dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor(all_segment_ids, dtype=torch.long)\n",
    "    try:\n",
    "        all_label_ids = torch.tensor(all_label_ids, dtype=torch.float32)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return all_input_ids, all_input_mask,  all_segment_ids, all_label_ids\n",
    "\n",
    "print('Def functions done! Time past %.2f secs' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019778,
     "end_time": "2021-06-23T20:14:37.803798",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.784020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing data to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:37.850342Z",
     "iopub.status.busy": "2021-06-23T20:14:37.849839Z",
     "iopub.status.idle": "2021-06-23T20:14:41.227556Z",
     "shell.execute_reply": "2021-06-23T20:14:41.228256Z",
     "shell.execute_reply.started": "2021-06-23T18:26:41.66638Z"
    },
    "papermill": {
     "duration": 3.404492,
     "end_time": "2021-06-23T20:14:41.228410",
     "exception": false,
     "start_time": "2021-06-23T20:14:37.823918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing...\n",
      "Done! Time past 4.43 secs\n"
     ]
    }
   ],
   "source": [
    "debug = False;\n",
    "\n",
    "print('Loading data...')\n",
    "df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
    "\n",
    "if debug:\n",
    "    df = df.loc[:25]\n",
    "test_ids = df['id'].tolist()\n",
    "\n",
    "\n",
    "df['comment_text'] = df['comment_text'].astype(str)\n",
    "print('Preprocessing...')\n",
    "\n",
    "df['comment_text']= preprocess(df['comment_text'])\n",
    "print('Done! Time past %.2f secs' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020697,
     "end_time": "2021-06-23T20:14:41.270249",
     "exception": false,
     "start_time": "2021-06-23T20:14:41.249552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading Train & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:41.347357Z",
     "iopub.status.busy": "2021-06-23T20:14:41.346439Z",
     "iopub.status.idle": "2021-06-23T20:14:58.680764Z",
     "shell.execute_reply": "2021-06-23T20:14:58.680283Z",
     "shell.execute_reply.started": "2021-06-23T18:26:52.947292Z"
    },
    "papermill": {
     "duration": 17.379361,
     "end_time": "2021-06-23T20:14:58.680895",
     "exception": false,
     "start_time": "2021-06-23T20:14:41.301534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:58.728242Z",
     "iopub.status.busy": "2021-06-23T20:14:58.727673Z",
     "iopub.status.idle": "2021-06-23T20:14:58.731407Z",
     "shell.execute_reply": "2021-06-23T20:14:58.730977Z",
     "shell.execute_reply.started": "2021-06-23T18:27:23.000486Z"
    },
    "papermill": {
     "duration": 0.029252,
     "end_time": "2021-06-23T20:14:58.731511",
     "exception": false,
     "start_time": "2021-06-23T20:14:58.702259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PORTER_STEMMER = PorterStemmer()\n",
    "LANCASTER_STEMMER = LancasterStemmer()\n",
    "SNOWBALL_STEMMER = SnowballStemmer(\"english\")\n",
    "\n",
    "def word_forms(word):\n",
    "    yield word\n",
    "    yield word.lower()\n",
    "    yield word.upper()\n",
    "    yield word.capitalize()\n",
    "    yield PORTER_STEMMER.stem(word)\n",
    "    yield LANCASTER_STEMMER.stem(word)\n",
    "    yield SNOWBALL_STEMMER.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:58.777473Z",
     "iopub.status.busy": "2021-06-23T20:14:58.776940Z",
     "iopub.status.idle": "2021-06-23T20:14:58.780239Z",
     "shell.execute_reply": "2021-06-23T20:14:58.780675Z",
     "shell.execute_reply.started": "2021-06-23T18:27:26.310282Z"
    },
    "papermill": {
     "duration": 0.028505,
     "end_time": "2021-06-23T20:14:58.780802",
     "exception": false,
     "start_time": "2021-06-23T20:14:58.752297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maybe_get_embedding(word, model):\n",
    "    for form in word_forms(word):\n",
    "        if form in model:\n",
    "            return model[form]\n",
    "\n",
    "    word = word.strip(\"-'\")\n",
    "    for form in word_forms(word):\n",
    "        if form in model:\n",
    "            return model[form]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020574,
     "end_time": "2021-06-23T20:14:58.822040",
     "exception": false,
     "start_time": "2021-06-23T20:14:58.801466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bert Large V2 99bin 250seq Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:14:58.890281Z",
     "iopub.status.busy": "2021-06-23T20:14:58.889749Z",
     "iopub.status.idle": "2021-06-23T20:39:26.820836Z",
     "shell.execute_reply": "2021-06-23T20:39:26.821259Z",
     "shell.execute_reply.started": "2021-06-23T18:27:48.766038Z"
    },
    "papermill": {
     "duration": 1467.978585,
     "end_time": "2021-06-23T20:39:26.821412",
     "exception": false,
     "start_time": "2021-06-23T20:14:58.842827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Time past 131.88 secs\n",
      "Loading model from ../input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/ ...\n",
      "Done! Time past 158.32 secs\n",
      "Predicting model Bert Large\n",
      "Done! Time past 1490.00 secs\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_dir = '../input/jigsawmodels/bert_large_v2_99bin_250seq/bert_large_v2_99bin_250seq/'\n",
    "    max_seq_length = 250\n",
    "    short_length = 100\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_dir, do_lower_case=True)\n",
    "    print('Converting data to sequences...')\n",
    "    test_data = apply_by_multiprocessing(df, convert_line, axis=1, max_seq_length=max_seq_length, tokenizer=tokenizer, model_name='bert', workers=4)  # takes 2 mins\n",
    "    all_input_ids, all_input_mask,  all_segment_ids, all_label_ids = get_input_data(test_data)\n",
    "    long_idx = (all_input_ids[:, short_length-max_seq_length:].sum(1) > 0).nonzero().squeeze().numpy()\n",
    "    short_idx = (all_input_ids[:, short_length-max_seq_length:].sum(1) == 0).nonzero().squeeze().numpy()\n",
    "    print('Done! Time past %.2f secs' % (time.time() - start_time))\n",
    "\n",
    "    # Load a trained model and vocabulary that you have fine-tuned\n",
    "    print('Loading model from %s ...' % model_dir)\n",
    "    bert_config = BertConfig(os.path.join(model_dir, 'config.json'))\n",
    "    model = BertForJigsaw(bert_config, out_dim=99)\n",
    "    model.load_state_dict(torch.load('%s/pytorch_model.bin' % model_dir))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print('Done! Time past %.2f secs' % (time.time() - start_time))\n",
    "\n",
    "    print('Predicting model Bert Large')\n",
    "    \n",
    "    predictions_bert_large = np.zeros(df.shape[0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate([short_idx, long_idx]):\n",
    "            test_data = TensorDataset(all_input_ids[idx], all_input_mask[idx], all_segment_ids[idx]) if i == 1 else \\\n",
    "                        TensorDataset(all_input_ids[idx, :short_length], all_input_mask[idx, :short_length], all_segment_ids[idx, :short_length])\n",
    "            test_sampler = SequentialSampler(test_data)\n",
    "            test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "            pred = []\n",
    "            for input_ids, input_mask, segment_ids in tqdm(test_dataloader):\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_mask = input_mask.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "\n",
    "                logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "                logits = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "                pred.append(logits)\n",
    "            predictions_bert_large[idx] = np.vstack(pred).mean(1)\n",
    "\n",
    "    print('Done! Time past %.2f secs' % (time.time() - start_time))\n",
    "except:\n",
    "    print('Something wrong with Bert Large.')\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:39:26.871406Z",
     "iopub.status.busy": "2021-06-23T20:39:26.870846Z",
     "iopub.status.idle": "2021-06-23T20:39:26.874747Z",
     "shell.execute_reply": "2021-06-23T20:39:26.875237Z",
     "shell.execute_reply.started": "2021-06-23T19:31:47.185819Z"
    },
    "papermill": {
     "duration": 0.030812,
     "end_time": "2021-06-23T20:39:26.875419",
     "exception": false,
     "start_time": "2021-06-23T20:39:26.844607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.zeros(df.shape[0])\n",
    "\n",
    "try:\n",
    "    predictions += predictions_bert_large * 1.0 \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T20:39:26.925772Z",
     "iopub.status.busy": "2021-06-23T20:39:26.925275Z",
     "iopub.status.idle": "2021-06-23T20:39:27.385136Z",
     "shell.execute_reply": "2021-06-23T20:39:27.384662Z",
     "shell.execute_reply.started": "2021-06-23T19:31:58.966622Z"
    },
    "papermill": {
     "duration": 0.486331,
     "end_time": "2021-06-23T20:39:27.385272",
     "exception": false,
     "start_time": "2021-06-23T20:39:26.898941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': df['id'],\n",
    "    'prediction': predictions_bert_large \n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pipreqs' from 'C:\\\\Users\\\\Raisul Islam\\\\anaconda3\\\\lib\\\\site-packages\\\\pipreqs\\\\__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pipreqs\n",
    "pipreqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1509.11879,
   "end_time": "2021-06-23T20:39:30.333872",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-23T20:14:21.215082",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
